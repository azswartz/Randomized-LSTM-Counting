{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-Diff-Counter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI4mQnD8jd1z",
        "colab_type": "text"
      },
      "source": [
        "# 05 Differentiable Counter\n",
        "\n",
        "Here is a differentiable counter for the LSTM to learn to use to count numbers. The counter works as follows:\n",
        "\n",
        "\n",
        "*   Upon seeing a sequence element $x_i$, the LSTM predicts a value $0 \\le r_i \\le 1$, which corresponds to the probability that the counter should be incremented by 1.\n",
        "*   The total count for a sequence is then $c=\\sum_i r_i$\n",
        "* The target for the sequence is $\\sum_i (x_i = 1)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajix1a-JSMYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGRIv7E4SScS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd drive/My\\ Drive/CS281\\ Final\\ Project"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYKWXcycBRSc",
        "colab_type": "text"
      },
      "source": [
        "## Package Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WsCo7B6jF3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = 'cuda'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from random import sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UKlKArUBTPJ",
        "colab_type": "text"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U1VtUxOz7f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Counter():\n",
        "    def __init__(self, hidden):\n",
        "        '''hidden is the number of hidden variables to use per cell'''\n",
        "        self.hidden = hidden\n",
        "        #this LSTM goes from input [batch x length x 1] to output [batch x length x hidden]\n",
        "        self.lstm = nn.LSTM(1, hidden, batch_first=True).double().cuda() \n",
        "\n",
        "        #this matrix transforms from [1 x hidden] to [1 x 1]\n",
        "        self.combine = torch.randn([hidden,1], dtype=float, device=device, requires_grad=True) \n",
        "\n",
        "        params = list(self.lstm.parameters())\n",
        "        params.append(self.combine)\n",
        "        self.optimizer = optim.Adam(params)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_sequence(seq):\n",
        "        '''converts a set of sequences with the same length from array or numpy into a correctly formatted tensor.\n",
        "        Shape: [batch x length x 1]'''\n",
        "        seq = torch.tensor(seq, device=device).double()\n",
        "        seq = seq.reshape([len(seq), -1, 1])\n",
        "        return seq\n",
        "\n",
        "    def predict(self, sequence):\n",
        "        '''takes a tensor, predicts the sum of the tensor, and compares to the actual sum of the tensor. \n",
        "        Returns the loss and the predicted sum'''\n",
        "\n",
        "        h = torch.zeros([1,sequence.shape[0],self.hidden]).double().cuda()\n",
        "        c = torch.zeros([1,sequence.shape[0],self.hidden]).double().cuda()\n",
        "\n",
        "        o, _ = self.lstm(sequence)\n",
        "        add = torch.sigmoid(o @ self.combine)\n",
        "        count = add.sum(1).squeeze(1)\n",
        "        true = sequence.sum(1).squeeze(1)\n",
        "        loss = (count - true).pow(2)\n",
        "        return loss, count\n",
        "\n",
        "    def predict_multilength(self, sequences):\n",
        "        '''Takes a list of batches of tensors of different length. Predicts on each batch. Sums up the loss. Reduces to a single mean'''\n",
        "        loss = torch.tensor(0, device=device).double()\n",
        "        count= torch.tensor(0, device=device).double()\n",
        "        for s in sequences:\n",
        "            res    = self.predict(s)[0]\n",
        "            count += res.shape[0]\n",
        "            loss  += res.sum()\n",
        "        return loss / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWFnUlWBqLM",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvC9waVe4EGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(length, total):\n",
        "    counts = np.random.dirichlet((np.arange(length)+1)**2) * total * 0.9\n",
        "    counts = np.round(counts).astype(int)\n",
        "\n",
        "    train_set = []\n",
        "    val_set = []\n",
        "    test_set = []\n",
        "\n",
        "    for i in range(1,length+1):\n",
        "        if counts[i-1] == 0:\n",
        "            continue\n",
        "        seqs = np.random.randint(0,2, size=[counts[i-1],i])\n",
        "        seqs = np.unique(seqs, axis=0)\n",
        "        try:\n",
        "            train, val = train_test_split(seqs, test_size=2/9, shuffle=True)\n",
        "            train = Counter.convert_sequence(train)\n",
        "            val = Counter.convert_sequence(val)\n",
        "            train_set.append(train)\n",
        "            val_set.append(val)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    counts = np.random.dirichlet((np.arange(length, 2*length)+1)**2) * total * 0.1\n",
        "    counts = np.round(counts).astype(int)\n",
        "    for i in range(length):\n",
        "        if counts[i] == 0:\n",
        "            continue\n",
        "        seqs = np.random.randint(0,2, size=[counts[i],i+length+1])\n",
        "        seqs = np.unique(seqs, axis=0)\n",
        "        test = Counter.convert_sequence(seqs)\n",
        "        test_set.append(test)\n",
        "\n",
        "    return train_set, val_set, test_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpsLBzjBjZmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate all the strings and partition into train and test\n",
        "length = 64\n",
        "hidden = 10\n",
        "\n",
        "output_folder = \"Part-5-Outputs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V28nvi7EGArd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# print(length)\n",
        "# depth = 100000\n",
        "# train, val, test = generate_data(length,depth)\n",
        "\n",
        "# with open(\"%s/Data.pickle\"%output_folder, \"wb\") as f:\n",
        "#     pickle.dump([train, val, test], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k82PKEhGETm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"%s/Data.pickle\"%output_folder, \"rb\") as f:\n",
        "    train, val, test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIQ6ykY8G65T",
        "colab_type": "code",
        "outputId": "b67f22bf-0c2c-41d4-ea3d-47cf38478fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "trainsize = sum([x.shape[0] for x in train])\n",
        "valsize = sum([x.shape[0] for x in val])\n",
        "testsize = sum([x.shape[0] for x in test])\n",
        "print(trainsize, valsize, testsize)\n",
        "\n",
        "total = trainsize+valsize+testsize\n",
        "print(\"Total:\",total)\n",
        "print(\"Fraction %.3f %.3f %.3f\"%(trainsize/total, valsize/total, testsize/total))\n",
        "\n",
        "print(\"Train    length range: %d-%d\"%(min([x.shape[1] for x in train]), max([x.shape[1] for x in train])))\n",
        "print(\"Validate length range: %d-%d\"%(min([x.shape[1] for x in val]), max([x.shape[1] for x in val])))\n",
        "print(\"Test     length range: %d-%d\"%(min([x.shape[1] for x in test]), max([x.shape[1] for x in test])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69924 20015 10003\n",
            "Total: 99942\n",
            "Fraction 0.700 0.200 0.100\n",
            "Train    length range: 2-64\n",
            "Validate length range: 2-64\n",
            "Test     length range: 65-128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO19JkYIXSAU",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsuiwPh729fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train over all the training data\n",
        "model = Counter(hidden=hidden)\n",
        "\n",
        "history = []\n",
        "best = float('inf')\n",
        "patience = 10\n",
        "tol = 0.001\n",
        "count = 0\n",
        "\n",
        "for epoch in range(1000000): \n",
        "    shuffle(train)\n",
        "    shuffle(val)\n",
        "    if epoch % 100 == 0:\n",
        "        train_loss = model.predict_multilength(train).item()\n",
        "        with torch.no_grad():\n",
        "            val_loss = model.predict_multilength(val).item()\n",
        "        history.append([train_loss, val_loss])\n",
        "        print(\"Epoch: %5d. Train Loss: %7.3f. Validation Loss: %7.3f\"%(epoch, train_loss, val_loss))\n",
        "\n",
        "        if val_loss + tol < best:\n",
        "            best = val_loss\n",
        "            count = 0\n",
        "        else:\n",
        "            count += 1\n",
        "        if count >= patience:\n",
        "            break\n",
        "\n",
        "    #take the average loss over all the train data\n",
        "    loss = model.predict_multilength(train)   \n",
        "    #and update\n",
        "    model.optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    model.optimizer.step()\n",
        "\n",
        "# history = np.array(history)\n",
        "# np.save(\"%s/Train-History\"%output_folder, history)\n",
        "# torch.save(model, \"%s/Model\"%output_folder)\n",
        "\n",
        "# #display testing results\n",
        "# loss = model.predict_multilength(test)\n",
        "# print(\"Average Test Loss:\", loss.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azs8MF9xXe4v",
        "colab_type": "text"
      },
      "source": [
        "## Results Evaluation\n",
        "\n",
        "Deliverable for this notebook: the main figure to get from this notebook should be a plot of string length versus prediction accuracy. Generate a string of length $n$ where each digit is 1 with a probability of 10% or so, and evaluate the loss of the network on that string. Run $n$ from $65$ to $10,000$ or so (whatever is a reasonable place to stop)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuDksNrpXgGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = np.load(\"%s/Train-History.npy\"%output_folder)\n",
        "train_loss = history[:,0]\n",
        "val_loss = history[:,1]\n",
        "model = torch.load(\"%s/Model\"%output_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n89feiojUKS",
        "colab_type": "code",
        "outputId": "a133ceca-8265-4e6a-b3d8-7549b6a063d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss = model.predict_multilength(test)\n",
        "print(\"Average Test Loss:\", loss.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Test Loss: 0.0009120174796806725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHesLDnUjnPy",
        "colab_type": "code",
        "outputId": "3afd8ec6-de14-4bb2-bfec-f85764a3b0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#print the true sum and predicted sum for one string of each length\n",
        "for size in test:\n",
        "    sample = size[np.random.choice(size.shape[0], 1)]\n",
        "    print(\"Length: %3d Sum: %3d Pred: %7.4f\"%(sample.shape[1], int(sample.cpu().numpy().sum()), model.predict(sample)[1].item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length:  65 Sum:  31 Pred: 30.9915\n",
            "Length:  66 Sum:  27 Pred: 26.9762\n",
            "Length:  67 Sum:  30 Pred: 30.0075\n",
            "Length:  68 Sum:  30 Pred: 30.0223\n",
            "Length:  69 Sum:  28 Pred: 28.0328\n",
            "Length:  70 Sum:  36 Pred: 36.0122\n",
            "Length:  71 Sum:  39 Pred: 39.0389\n",
            "Length:  72 Sum:  29 Pred: 28.9874\n",
            "Length:  73 Sum:  33 Pred: 33.0060\n",
            "Length:  74 Sum:  38 Pred: 38.0294\n",
            "Length:  75 Sum:  36 Pred: 35.9969\n",
            "Length:  76 Sum:  40 Pred: 40.0073\n",
            "Length:  77 Sum:  34 Pred: 33.9626\n",
            "Length:  78 Sum:  37 Pred: 36.9973\n",
            "Length:  79 Sum:  43 Pred: 43.0261\n",
            "Length:  80 Sum:  37 Pred: 37.0211\n",
            "Length:  81 Sum:  36 Pred: 35.9805\n",
            "Length:  82 Sum:  49 Pred: 48.9899\n",
            "Length:  83 Sum:  34 Pred: 33.9506\n",
            "Length:  84 Sum:  36 Pred: 36.0293\n",
            "Length:  85 Sum:  30 Pred: 30.0006\n",
            "Length:  86 Sum:  43 Pred: 43.0322\n",
            "Length:  87 Sum:  50 Pred: 49.9885\n",
            "Length:  88 Sum:  45 Pred: 44.9416\n",
            "Length:  89 Sum:  46 Pred: 46.0317\n",
            "Length:  90 Sum:  49 Pred: 48.9772\n",
            "Length:  91 Sum:  38 Pred: 38.0174\n",
            "Length:  92 Sum:  47 Pred: 46.9660\n",
            "Length:  93 Sum:  51 Pred: 51.0202\n",
            "Length:  94 Sum:  41 Pred: 41.0271\n",
            "Length:  95 Sum:  41 Pred: 40.9799\n",
            "Length:  96 Sum:  46 Pred: 45.9821\n",
            "Length:  97 Sum:  49 Pred: 48.9827\n",
            "Length:  98 Sum:  44 Pred: 44.0328\n",
            "Length:  99 Sum:  39 Pred: 38.9912\n",
            "Length: 100 Sum:  44 Pred: 43.9735\n",
            "Length: 101 Sum:  55 Pred: 54.9526\n",
            "Length: 102 Sum:  46 Pred: 45.9691\n",
            "Length: 103 Sum:  53 Pred: 52.9998\n",
            "Length: 104 Sum:  46 Pred: 46.0430\n",
            "Length: 105 Sum:  56 Pred: 56.0064\n",
            "Length: 106 Sum:  62 Pred: 61.9383\n",
            "Length: 107 Sum:  46 Pred: 45.9666\n",
            "Length: 108 Sum:  59 Pred: 59.0164\n",
            "Length: 109 Sum:  56 Pred: 56.0279\n",
            "Length: 110 Sum:  55 Pred: 54.9695\n",
            "Length: 111 Sum:  60 Pred: 59.9933\n",
            "Length: 112 Sum:  51 Pred: 50.9751\n",
            "Length: 113 Sum:  61 Pred: 60.9517\n",
            "Length: 114 Sum:  65 Pred: 65.0053\n",
            "Length: 115 Sum:  56 Pred: 55.9864\n",
            "Length: 116 Sum:  46 Pred: 45.9573\n",
            "Length: 117 Sum:  53 Pred: 53.0050\n",
            "Length: 118 Sum:  52 Pred: 51.9887\n",
            "Length: 119 Sum:  55 Pred: 54.9803\n",
            "Length: 120 Sum:  61 Pred: 60.9899\n",
            "Length: 121 Sum:  59 Pred: 58.9811\n",
            "Length: 122 Sum:  57 Pred: 57.0157\n",
            "Length: 123 Sum:  67 Pred: 67.0410\n",
            "Length: 124 Sum:  53 Pred: 52.9799\n",
            "Length: 125 Sum:  63 Pred: 62.9752\n",
            "Length: 126 Sum:  73 Pred: 73.0010\n",
            "Length: 127 Sum:  65 Pred: 64.9686\n",
            "Length: 128 Sum:  63 Pred: 63.0108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpe-SFQmpziM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}