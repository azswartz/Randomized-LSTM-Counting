{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-Unequal-Length.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI4mQnD8jd1z",
        "colab_type": "text"
      },
      "source": [
        "# 04 Unequal Length\n",
        "\n",
        "I train the LSTM on all strings of length $\\le k$, test the LSTM on all strings of length $>k, \\le 2k$ and then gradually increase $k$ from 16 to 128. I just changed the data generation, so everything else should be the same.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajix1a-JSMYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGRIv7E4SScS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd drive/My\\ Drive/CS281\\ Final\\ Project"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYKWXcycBRSc",
        "colab_type": "text"
      },
      "source": [
        "## Package Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WsCo7B6jF3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = 'cuda'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UKlKArUBTPJ",
        "colab_type": "text"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U1VtUxOz7f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Counter():\n",
        "    def __init__(self, hidden):\n",
        "        '''hidden is the number of hidden variables to use per cell'''\n",
        "\n",
        "        #this LSTM goes from input [batch x length x 1] to output [batch x length x hidden]\n",
        "        self.lstm = nn.LSTM(1, hidden, batch_first=True).double().cuda() \n",
        "\n",
        "        #this matrix transforms from [1 x hidden] to [1 x 1]\n",
        "        self.combine = torch.randn([hidden,1], dtype=float, device=device, requires_grad=True) \n",
        "\n",
        "        params = list(self.lstm.parameters())\n",
        "        params.append(self.combine)\n",
        "        self.optimizer = optim.Adam(params)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_sequence(seq):\n",
        "        '''converts a set of sequences with the same length from array or numpy into a correctly formatted tensor.\n",
        "        Shape: [batch x length x 1]'''\n",
        "        seq = torch.tensor(seq, device=device).double()\n",
        "        seq = seq.reshape([len(seq), -1, 1])\n",
        "        return seq\n",
        "\n",
        "    def predict(self, sequence):\n",
        "        '''takes a tensor, predicts the sum of the tensor, and compares to the actual sum of the tensor. \n",
        "        Returns the loss and the predicted sum'''\n",
        "        pred, _ = self.lstm(sequence)\n",
        "        pred = pred[:,-1,:] @ self.combine \n",
        "        #the second index is the rolling output. The final output is the last element in that index\n",
        "\n",
        "        loss = (pred - sequence.sum(1)).pow(2)\n",
        "        return loss, pred\n",
        "\n",
        "    def predict_multilength(self, sequences):\n",
        "        '''Takes a list of batches of tensors of different length. Predicts on each batch. Sums up the loss. Reduces to a single mean'''\n",
        "        loss = torch.tensor(0, device=device).double()\n",
        "        count= torch.tensor(0, device=device).double()\n",
        "        for s in sequences:\n",
        "            pred = self.predict(s)[0]\n",
        "            count += pred.shape[0]\n",
        "            loss += pred.sum()\n",
        "        return loss / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWFnUlWBqLM",
        "colab_type": "text"
      },
      "source": [
        "## Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvC9waVe4EGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(length, total):\n",
        "    counts = np.random.dirichlet(np.arange(length)**2+1) * total * 0.9\n",
        "    counts = np.round(counts).astype(int)\n",
        "\n",
        "    train_set = []\n",
        "    val_set = []\n",
        "    test_set = []\n",
        "\n",
        "    for i in range(1,length+1):\n",
        "        if counts[i-1] == 0:\n",
        "            continue\n",
        "        seqs = np.random.randint(0,2, size=[counts[i-1],i])\n",
        "        seqs = np.unique(seqs, axis=0)\n",
        "        try:\n",
        "            train, val = train_test_split(seqs, test_size=2/9, shuffle=True)\n",
        "            train = Counter.convert_sequence(train)\n",
        "            val = Counter.convert_sequence(val)\n",
        "            train_set.append(train)\n",
        "            val_set.append(val)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    counts = np.random.dirichlet(np.arange(length, 2*length)**2+1) * total * 0.1\n",
        "    counts = np.round(counts).astype(int)\n",
        "    for i in range(length):\n",
        "        if counts[i] == 0:\n",
        "            continue\n",
        "        seqs = np.random.randint(0,2, size=[counts[i],i+length+1])\n",
        "        seqs = np.unique(seqs, axis=0)\n",
        "        test = Counter.convert_sequence(seqs)\n",
        "        test_set.append(test)\n",
        "\n",
        "    trainsize = sum([x.shape[0] for x in train_set])\n",
        "    valsize = sum([x.shape[0] for x in val_set])\n",
        "    testsize = sum([x.shape[0] for x in test_set])\n",
        "    print(trainsize, valsize, testsize)\n",
        "\n",
        "    total = trainsize+valsize+testsize\n",
        "    print(\"Total:\",total)\n",
        "    print(\"Fraction %.3f %.3f %.3f\"%(trainsize/total, valsize/total, testsize/total))\n",
        "    return train_set, val_set, test_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf4TPAXBV7we",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val, test = generate_data(16,100000)\n",
        "for x in train:\n",
        "    print(x.shape)\n",
        "for x in val:\n",
        "    print(x.shape)\n",
        "for x in test:\n",
        "    print(x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsuiwPh729fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate all the strings and partition into train and test\n",
        "length = 16\n",
        "hidden = 5\n",
        "\n",
        "print(length)\n",
        "depth = 100000\n",
        "train, val, test = generate_data(length,depth)\n",
        "#train over all the training data\n",
        "model = Counter(hidden=hidden)\n",
        "\n",
        "history = []\n",
        "best = float('inf')\n",
        "patience = 10\n",
        "tol = 0.001\n",
        "count = 0\n",
        "\n",
        "for epoch in range(1000000): \n",
        "    shuffle(train)\n",
        "    shuffle(val)\n",
        "    if epoch % 100 == 0:\n",
        "        train_loss = model.predict_multilength(train).item()\n",
        "        with torch.no_grad():\n",
        "            val_loss = model.predict_multilength(val).item()\n",
        "        history.append([train_loss, val_loss])\n",
        "        print(\"Epoch: %5d. Train Loss: %7.3f. Validation Loss: %7.3f\"%(epoch, train_loss, val_loss))\n",
        "\n",
        "        if val_loss + tol < best:\n",
        "            best = val_loss\n",
        "            count = 0\n",
        "        else:\n",
        "            count += 1\n",
        "        if count >= patience:\n",
        "            break\n",
        "\n",
        "    #take the average loss over all the train data\n",
        "    loss = model.predict_multilength(train)   \n",
        "    #and update\n",
        "    model.optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    model.optimizer.step()\n",
        "history = np.array(history)\n",
        "np.save(\"Part-3-Outputs/Train-%d-%d\"%(hidden, length), history)\n",
        "torch.save(model, \"Part-3-Outputs/Model-%d-%d\"%(hidden, length))\n",
        "\n",
        "#display testing results\n",
        "loss = model.predict_multilength(test)\n",
        "print(\"Average Test Loss:\", loss.item())\n",
        "\n",
        "with open(\"Part-3-Outputs/TrainResults.txt\", 'a') as f:\n",
        "    f.write(\"%3d %9.5f\\n\"%(length, loss.item()))\n",
        "\n",
        "with open(\"Part-3-Outputs/Test-%d-%d.txt\"%(hidden, length), 'w') as f:\n",
        "    for seq in test:\n",
        "        loss, pred = model.predict(seq)\n",
        "        for k in range(len(seq)):\n",
        "            string = seq[k].int().cpu().numpy().flatten()\n",
        "            f.write(\"%s -- %d -- %.3f\\n\"%(str(string), sum(string), pred[k].item()))\n",
        "\n",
        "print('\\n\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guCr_i5zx9MQ",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ouKEYhCIfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReadOutFile(h, l):\n",
        "  file_name = 'Part-4-Outputs/Run' + str(h) + '_' + str(l) + '.out'\n",
        "  s = open(file_name)\n",
        "  line_num = 0\n",
        "  epoch, train_loss, val_loss = [], [], []\n",
        "\n",
        "  for line in s:\n",
        "    line_num += 1\n",
        "    if line_num == 2:\n",
        "      train_num, val_num, test_num = line.split()\n",
        "      \n",
        "    elif line_num > 4 and len(line.split()) == 8:\n",
        "      _, x, _, _, y, _, _, z =  line.split()\n",
        "      epoch.append(float(x.rstrip('.')))\n",
        "      train_loss.append(float(y.rstrip('.')))\n",
        "      val_loss.append(float(z))\n",
        "\n",
        "    elif line_num > 4 and len(line.split()) == 4:\n",
        "      _, _, _, avg_test_loss = line.split()\n",
        "    \n",
        "  return epoch, train_loss, val_loss, float(avg_test_loss)\n",
        "\n",
        "def PlotOutFile(h, l):\n",
        "  epoch, train_loss, val_loss, _ = ReadOutFile(h, l)\n",
        "  plt.plot(epoch, train_loss, c = 'r', label = 'Training Loss', alpha = 0.7)\n",
        "  plt.plot(epoch, val_loss,  c = 'b', label = 'Validation Loss', alpha = 0.7)\n",
        "  plt.title(\"Hidden Units = \" + str(h) + \"; Length = \" + str(l))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"MSE\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "def PlotMultipleOutFilesConstL(hs, l):\n",
        "  for h in hs:\n",
        "    epoch, train_loss, val_loss, _ = ReadOutFile(h, l)\n",
        "    plt.plot(epoch, val_loss, label = str(h) + ' Hidden Units' , alpha = 0.7)\n",
        "  plt.xscale('log')\n",
        "  plt.title(\"Length = \" + str(l))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Validation MSE\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "def PlotMultipleOutFilesConstH(h, ls):\n",
        "  for l in ls:\n",
        "    epoch, train_loss, val_loss, _ = ReadOutFile(h, l)\n",
        "    plt.plot(epoch, val_loss, label = 'Length = ' + str(l) , alpha = 0.7)\n",
        "  plt.xscale('log')\n",
        "  plt.title(str(h) + \" Hidden Units\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Validation MSE\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "def PlotMultipleOutFilesConstHZoomed(h, ls, print_epoch = 15000):\n",
        "  for l in ls:\n",
        "    epoch, train_loss, val_loss, _ = ReadOutFile(h, l)\n",
        "    choosen_epoch, choosen_val_loss = [], []\n",
        "    for i in range(len(epoch)):\n",
        "      if epoch[i] > print_epoch:\n",
        "        choosen_epoch.append(epoch[i])\n",
        "        choosen_val_loss.append(val_loss[i])\n",
        "    plt.plot(choosen_epoch, choosen_val_loss, label = 'Length = ' + str(l) , alpha = 0.7)\n",
        "  plt.xscale('log')\n",
        "  plt.title(str(h) + \" Hidden Units\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Validation MSE\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "def PlotTestErrorConstH(h, ls):\n",
        "  test_error  = []\n",
        "  for l in ls:\n",
        "    _, _, _, avg_test_loss = ReadOutFile(h, l)\n",
        "    test_error.append(avg_test_loss)\n",
        "  \n",
        "  plt.plot(ls, test_error)\n",
        "  plt.title(str(h) + \" Hidden Units\")\n",
        "  plt.xlabel(\"Length\")\n",
        "  plt.ylabel(\"Test MSE\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm-K2Pe6KHGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "passes = []\n",
        "fails = []\n",
        "\n",
        "for h in range(1,8,2):\n",
        "  for l in range(16,257,16):\n",
        "    try:\n",
        "      epoch, train_loss, val_loss, avg_test_loss = ReadOutFile(h,l)\n",
        "      if avg_test_loss:\n",
        "        passes.append((h,l,len(epoch), train_loss[-1], val_loss[-1], avg_test_loss))\n",
        "      else:\n",
        "        fails.append((h,l,len(epoch), train_loss[-1], val_loss[-1], avg_test_loss))\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVsmArkVTCeh",
        "colab_type": "code",
        "outputId": "7132619a-32e3-4a93-82fc-ced5fdd17be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "max_possibles = []\n",
        "ks = []\n",
        "\n",
        "for h in range(1,8,2):\n",
        "  for l in range(16,129,16):\n",
        "    try:\n",
        "      weights = torch.load('Part-4-Outputs/Model-' + str(h) + '-' + str(l))\n",
        "      max_possibles += [float(sum(abs(weights.combine)))]\n",
        "      ks += [l]\n",
        "    except:\n",
        "      print(h,l)\n",
        "      continue\n",
        "\n",
        "plt.plot(np.linspace(0,128), np.linspace(0,128), color='k',label='y=x', alpha=0.7)\n",
        "\n",
        "plt.scatter(ks,max_possibles)\n",
        "plt.title(\"All fully trained models\")\n",
        "plt.xlabel(\"Length\")\n",
        "plt.ylabel(\"Max possible output\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 80\n",
            "1 96\n",
            "1 112\n",
            "1 128\n",
            "3 128\n",
            "5 128\n",
            "7 112\n",
            "7 128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDEmixUFY4wxWawoGGOMyfL/AaCy71xMcABoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oA2bUjzxwnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PlotMultipleOutFilesConstLZoomed(hs, l, print_epochs, xscale='log'):\n",
        "  for h in hs:\n",
        "    epoch, train_loss, val_loss, _ = ReadOutFile(h, l)\n",
        "    choosen_epoch, choosen_val_loss = [], []\n",
        "    for i in range(len(epoch)):\n",
        "      if epoch[i] in print_epochs:\n",
        "        choosen_epoch.append(epoch[i])\n",
        "        choosen_val_loss.append(val_loss[i])\n",
        "    plt.plot(choosen_epoch, choosen_val_loss, label = str(h) + ' Hidden Units'  , alpha = 0.7)\n",
        "  plt.xscale(xscale)\n",
        "  plt.title(\"Length = \" + str(l))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Validation MSE\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}