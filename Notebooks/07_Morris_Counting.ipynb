{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07-Morris-Counting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI4mQnD8jd1z",
        "colab_type": "text"
      },
      "source": [
        "# 07 Morris Counting\n",
        "\n",
        "Here is an implementation of Morris counting by hand, and then with machine learning. For this notebook, the random bits are preprocessed to be in the correct scale so that a random bit of 0 means to increment the counter and anything else means not to. This means that essentially, this network just needs to learn the `and` function and increment the counter whenever the string has a 1 and the random bit is 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajix1a-JSMYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGRIv7E4SScS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd drive/My\\ Drive/CS281\\ Final\\ Project"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYKWXcycBRSc",
        "colab_type": "text"
      },
      "source": [
        "## Package Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s19LqsST4SRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WsCo7B6jF3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = 'cuda'\n",
        "\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0QdpRENO3R",
        "colab_type": "text"
      },
      "source": [
        "## Manual Counter Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLaPrg3GN9QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def morris_count(seq):\n",
        "    '''Takes a sequence, and returns the log output of a Morris counter as well as the random bits used to make the counter'''\n",
        "    x = 0 \n",
        "    bits = []\n",
        "    for i in seq:\n",
        "        noise = np.random.randint(0, 2**x)\n",
        "        bits.append(noise)\n",
        "        if i == 1 and noise == 0:\n",
        "            x += 1\n",
        "    return x, bits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UKlKArUBTPJ",
        "colab_type": "text"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U1VtUxOz7f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Counter():\n",
        "    def __init__(self, hidden, input_size=1):\n",
        "        '''hidden is the number of hidden variables to use per cell'''\n",
        "        self.hidden = hidden\n",
        "        #this LSTM goes from input [batch x length x 1] to output [batch x length x hidden]\n",
        "        self.lstm = nn.LSTM(hidden_size=hidden, batch_first=True, input_size=input_size).double().cuda() \n",
        "\n",
        "        #this matrix transforms from [1 x hidden] to [1 x 1]\n",
        "        self.combine = torch.randn([hidden,1], dtype=float, device=device, requires_grad=True) \n",
        "\n",
        "        params = list(self.lstm.parameters())\n",
        "        params.append(self.combine)\n",
        "        self.optimizer = optim.Adam(params)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_sequence(seq, input_size=1):\n",
        "        '''converts a set of sequences with the same length from array or numpy into a correctly formatted tensor.'''\n",
        "        seq = torch.tensor(seq, device=device).double()\n",
        "        seq = seq.reshape([len(seq), -1, input_size])\n",
        "        return seq\n",
        "\n",
        "    def predict(self, sequence, target):\n",
        "        '''takes a tensor, predicts the sum of the tensor, and compares to the target sum of the tensor. \n",
        "        Returns the loss and the predicted sum'''\n",
        "\n",
        "        h = torch.zeros([1,sequence.shape[0],self.hidden]).double().cuda()\n",
        "        c = torch.zeros([1,sequence.shape[0],self.hidden]).double().cuda()\n",
        "\n",
        "        o, _ = self.lstm(sequence)\n",
        "        add = torch.sigmoid(o @ self.combine)\n",
        "        count = add.sum(1).squeeze(1)\n",
        "        loss = (count - target).pow(2)\n",
        "        return loss, count\n",
        "\n",
        "    def predict_multilength(self, sequences, target):\n",
        "        '''Takes a list of batches of tensors of different length. Predicts on each batch. Sums up the loss. Reduces to a single mean'''\n",
        "        loss = torch.tensor(0, device=device).double()\n",
        "        count= torch.tensor(0, device=device).double()\n",
        "        for s,t in zip(sequences, target):\n",
        "            res    = self.predict(s,t)[0]\n",
        "            count += res.shape[0]\n",
        "            loss  += res.sum()\n",
        "        return loss / count\n",
        "\n",
        "    @staticmethod\n",
        "    def true_sum(sequence):\n",
        "        '''Determines the true sums of a batch of sequences to train against'''\n",
        "        comp = (sequence >= 0).float()\n",
        "        comp = comp.sum(1).squeeze(1)\n",
        "        return comp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWFnUlWBqLM",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HXETfIEZdFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_bits(dataset):\n",
        "    '''takes a dataset of sequences and runs the morris counter to get the random bits and the true labels'''\n",
        "    X_set = []\n",
        "    Y_set = []\n",
        "    for chunk in dataset:\n",
        "        converted = []\n",
        "        target = []\n",
        "        for s in chunk:\n",
        "            x, bits = morris_count(s)\n",
        "            converted.append(np.array([s,bits]).T)\n",
        "            target.append(x)\n",
        "        converted = np.array(converted).astype(float)\n",
        "        converted = Counter.convert_sequence(converted, input_size=2)\n",
        "        target = torch.tensor(target, device=device).double()\n",
        "        X_set.append(converted)\n",
        "        Y_set.append(target)\n",
        "    return X_set, Y_set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvC9waVe4EGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_data(length, total):\n",
        "    counts = np.random.dirichlet((np.arange(length)+1)**2) * total * 0.9\n",
        "    counts = np.round(counts).astype(int)\n",
        "\n",
        "    train_set = []\n",
        "    val_set = []\n",
        "    test_set = []\n",
        "\n",
        "    for i in range(1,length+1):\n",
        "        if counts[i-1] == 0:\n",
        "            continue\n",
        "        seqs = np.random.randint(0,2, size=[counts[i-1],i])\n",
        "        seqs = np.unique(seqs, axis=0)\n",
        "        try:\n",
        "            train, val = train_test_split(seqs, test_size=2/9, shuffle=True)\n",
        "            train_set.append(train)\n",
        "            val_set.append(val)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    counts = np.random.dirichlet((np.arange(length, 2*length)+1)**2) * total * 0.1\n",
        "    counts = np.round(counts).astype(int)\n",
        "    for i in range(length):\n",
        "        if counts[i] == 0:\n",
        "            continue\n",
        "        seqs = np.random.randint(0,2, size=[counts[i],i+length+1])\n",
        "        seqs = np.unique(seqs, axis=0)\n",
        "        test_set.append(seqs)\n",
        "\n",
        "    train_set = add_bits(train_set)\n",
        "    val_set = add_bits(val_set)\n",
        "    test_set = add_bits(test_set)\n",
        "\n",
        "    return train_set, val_set, test_set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ekLB3rz96d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate all the strings and partition into train and test\n",
        "length = 64\n",
        "hidden = 10\n",
        "depth = 100000\n",
        "\n",
        "output_folder = \"Part-7-Outputs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V28nvi7EGArd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train, val, test = generate_data(length,depth)\n",
        "\n",
        "# with open(\"%s/Data.pickle\"%output_folder, \"wb\") as f:\n",
        "#     pickle.dump([train, val, test], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k82PKEhGETm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"%s/Data.pickle\"%output_folder, \"rb\") as f:\n",
        "    train, val, test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DEtx6NKm9do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, train_y = train\n",
        "val, val_y = val\n",
        "test, test_y = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIQ6ykY8G65T",
        "colab_type": "code",
        "outputId": "93d7524b-2d30-441c-aa46-29072606d408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "trainsize = sum([x.shape[0] for x in train])\n",
        "valsize = sum([x.shape[0] for x in val])\n",
        "testsize = sum([x.shape[0] for x in test])\n",
        "print(trainsize, valsize, testsize)\n",
        "\n",
        "total = trainsize+valsize+testsize\n",
        "print(\"Total:\",total) \n",
        "print(\"Fraction %.3f %.3f %.3f\"%(trainsize/total, valsize/total, testsize/total))\n",
        "\n",
        "print(\"Train    string range: %d-%d\"%(min([x.shape[1] for x in train]), max([x.shape[1] for x in train])))\n",
        "print(\"Validate string range: %d-%d\"%(min([x.shape[1] for x in val]), max([x.shape[1] for x in val])))\n",
        "print(\"Test     string range: %d-%d\"%(min([x.shape[1] for x in test]), max([x.shape[1] for x in test])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69921 20011 9995\n",
            "Total: 99927\n",
            "Fraction 0.700 0.200 0.100\n",
            "Train    string range: 1-64\n",
            "Validate string range: 1-64\n",
            "Test     string range: 65-128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO19JkYIXSAU",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsuiwPh729fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train over all the training data\n",
        "model = Counter(hidden=hidden, input_size=2)\n",
        "\n",
        "history = []\n",
        "best = float('inf')\n",
        "patience = 10\n",
        "tol = 0.001\n",
        "count = 0\n",
        "\n",
        "for epoch in range(1000000): \n",
        "    # shuffle(train)\n",
        "    # shuffle(val)\n",
        "    if epoch % 100 == 0:\n",
        "        train_loss = model.predict_multilength(train, train_y).item()\n",
        "        with torch.no_grad():\n",
        "            val_loss = model.predict_multilength(val, val_y).item()\n",
        "        history.append([train_loss, val_loss])\n",
        "        print(\"Epoch: %5d. Train Loss: %7.3f. Validation Loss: %7.3f\"%(epoch, train_loss, val_loss))\n",
        "\n",
        "        if val_loss + tol < best:\n",
        "            best = val_loss\n",
        "            count = 0\n",
        "        else:\n",
        "            count += 1\n",
        "        if count >= patience:\n",
        "            break\n",
        "\n",
        "    #take the average loss over all the train data\n",
        "    loss = model.predict_multilength(train, train_y)   \n",
        "    #and update\n",
        "    model.optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    model.optimizer.step()\n",
        "\n",
        "# history = np.array(history)\n",
        "# np.save(\"%s/Train-History\"%output_folder, history)\n",
        "# torch.save(model, \"%s/Model\"%output_folder)\n",
        "\n",
        "# #display testing results\n",
        "# loss = model.predict_multilength(test)\n",
        "# print(\"Average Test Loss:\", loss.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azs8MF9xXe4v",
        "colab_type": "text"
      },
      "source": [
        "## Results Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuDksNrpXgGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = np.load(\"%s/Train-History.npy\"%output_folder)\n",
        "train_loss = history[:,0]\n",
        "val_loss = history[:,1]\n",
        "model = torch.load(\"%s/Model\"%output_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unX-NIDzdnG8",
        "colab_type": "code",
        "outputId": "cb6f2930-a62e-4d3d-8ad0-d6dd1dba6055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss = model.predict_multilength(test, test_y)\n",
        "print(\"Average Test Loss:\", loss.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Test Loss: 0.0014881722468963487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC2T9lnFu8Fn",
        "colab_type": "code",
        "outputId": "04782e5f-763a-4baa-fc33-cb3f72cdb0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "#sample sequence and random bits\n",
        "seq = test[-1][0].cpu().numpy()\n",
        "print(seq[:,0])\n",
        "print(seq[:,1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 0. 1. 0. 1. 0. 1.]\n",
            "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.\n",
            "  3. 10.  6.  7.  7. 14. 10.  9.  8.  5.  7. 10. 12. 10.  2.  0. 30. 26.\n",
            " 24. 14. 26.  8.  9.  9. 21.  2.  7. 22. 17. 21. 30. 11. 18. 16. 14. 25.\n",
            "  7. 28. 21. 14. 28. 29.  3. 21. 16. 16.  2. 17. 19. 19.  1. 30. 10. 19.\n",
            "  0. 59. 53. 19. 60.  0. 60.  2. 26. 22. 57. 59.  5. 63.  8. 43. 55. 28.\n",
            " 38. 32. 20. 33.  8. 20.  6.  6. 21. 43. 19. 58.  0. 18. 43. 22.  9. 19.\n",
            " 13.  9. 18. 30. 60. 61. 29. 61.  6. 28. 40. 14. 59. 10. 17. 51. 47.  2.\n",
            " 22. 30.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MArloZlnvDg0",
        "colab_type": "code",
        "outputId": "33e16e5e-f3dd-4b24-9b48-7617e7cfd964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#print the true sum and predicted sum for one string of each length\n",
        "for chunk, chunk_y in zip(test, test_y):\n",
        "    ind = np.random.choice(chunk.shape[0], 1)\n",
        "    sample = chunk[ind]\n",
        "    true_sum = chunk_y[ind]\n",
        "    print(\"Length: %3d Sum: %3d Pred: %7.4f\"%(sample.shape[1], true_sum, model.predict(sample, true_sum)[1].item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length:  65 Sum:   5 Pred:  4.9960\n",
            "Length:  66 Sum:   4 Pred:  4.0147\n",
            "Length:  67 Sum:   5 Pred:  4.9950\n",
            "Length:  68 Sum:   4 Pred:  3.9830\n",
            "Length:  69 Sum:   5 Pred:  5.0260\n",
            "Length:  70 Sum:   4 Pred:  4.0249\n",
            "Length:  71 Sum:   4 Pred:  4.0468\n",
            "Length:  72 Sum:   5 Pred:  5.0083\n",
            "Length:  73 Sum:   4 Pred:  3.9956\n",
            "Length:  74 Sum:   7 Pred:  7.0337\n",
            "Length:  75 Sum:   5 Pred:  4.9964\n",
            "Length:  76 Sum:   6 Pred:  6.0039\n",
            "Length:  77 Sum:   6 Pred:  5.9947\n",
            "Length:  78 Sum:   5 Pred:  5.0316\n",
            "Length:  79 Sum:   5 Pred:  5.0141\n",
            "Length:  80 Sum:   4 Pred:  4.0696\n",
            "Length:  81 Sum:   5 Pred:  5.0028\n",
            "Length:  82 Sum:   5 Pred:  4.9955\n",
            "Length:  83 Sum:   5 Pred:  5.0115\n",
            "Length:  84 Sum:   6 Pred:  5.9895\n",
            "Length:  85 Sum:   6 Pred:  6.0095\n",
            "Length:  86 Sum:   4 Pred:  4.0456\n",
            "Length:  87 Sum:   4 Pred:  4.0460\n",
            "Length:  88 Sum:   4 Pred:  4.0271\n",
            "Length:  89 Sum:   6 Pred:  6.0338\n",
            "Length:  90 Sum:   4 Pred:  4.0300\n",
            "Length:  91 Sum:   5 Pred:  5.0131\n",
            "Length:  92 Sum:   4 Pred:  4.0445\n",
            "Length:  93 Sum:   6 Pred:  6.0193\n",
            "Length:  94 Sum:   5 Pred:  5.0247\n",
            "Length:  95 Sum:   6 Pred:  6.0272\n",
            "Length:  96 Sum:   4 Pred:  4.0665\n",
            "Length:  97 Sum:   6 Pred:  5.9978\n",
            "Length:  98 Sum:   4 Pred:  4.0391\n",
            "Length:  99 Sum:   7 Pred:  7.0374\n",
            "Length: 100 Sum:   5 Pred:  5.0098\n",
            "Length: 101 Sum:   5 Pred:  5.0109\n",
            "Length: 102 Sum:   6 Pred:  6.0106\n",
            "Length: 103 Sum:   5 Pred:  5.0170\n",
            "Length: 104 Sum:   5 Pred:  5.0470\n",
            "Length: 105 Sum:   5 Pred:  5.0649\n",
            "Length: 106 Sum:   5 Pred:  5.0465\n",
            "Length: 107 Sum:   7 Pred:  7.0008\n",
            "Length: 108 Sum:   5 Pred:  5.0451\n",
            "Length: 109 Sum:   4 Pred:  4.0766\n",
            "Length: 110 Sum:   4 Pred:  4.0309\n",
            "Length: 111 Sum:   4 Pred:  4.0540\n",
            "Length: 112 Sum:   5 Pred:  5.0311\n",
            "Length: 113 Sum:   6 Pred:  6.0179\n",
            "Length: 114 Sum:   5 Pred:  5.0113\n",
            "Length: 115 Sum:   5 Pred:  5.0028\n",
            "Length: 116 Sum:   5 Pred:  5.0455\n",
            "Length: 117 Sum:   6 Pred:  5.9817\n",
            "Length: 118 Sum:   4 Pred:  4.0716\n",
            "Length: 119 Sum:   6 Pred:  6.0158\n",
            "Length: 120 Sum:   7 Pred:  7.0610\n",
            "Length: 121 Sum:   5 Pred:  5.0706\n",
            "Length: 122 Sum:   5 Pred:  5.0091\n",
            "Length: 123 Sum:   5 Pred:  5.0862\n",
            "Length: 124 Sum:   7 Pred:  7.0229\n",
            "Length: 125 Sum:   5 Pred:  5.0423\n",
            "Length: 126 Sum:   7 Pred:  6.9895\n",
            "Length: 127 Sum:   5 Pred:  5.0324\n",
            "Length: 128 Sum:   6 Pred:  6.0214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veZK51Vbvd9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}