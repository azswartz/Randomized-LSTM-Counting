{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08.2-Log-Bits.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI4mQnD8jd1z",
        "colab_type": "text"
      },
      "source": [
        "# 08.2 Log Bits\n",
        "\n",
        "Same thing as in 8.1, except instead of a $\\exp(x)$ activation on the random bits, its a $\\log(x^2)$ activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajix1a-JSMYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGRIv7E4SScS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd drive/My\\ Drive/CS281\\ Final\\ Project"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYKWXcycBRSc",
        "colab_type": "text"
      },
      "source": [
        "## Package Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s19LqsST4SRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WsCo7B6jF3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = 'cuda'\n",
        "\n",
        "from math import isclose\n",
        "from time import time\n",
        "import pickle\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0QdpRENO3R",
        "colab_type": "text"
      },
      "source": [
        "## Manual Counter Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLaPrg3GN9QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def morris_count(seq):\n",
        "    '''seq[:,0] is the sequence. seq[:,1] is the random floats.'''\n",
        "    x = 0\n",
        "    for i in seq:\n",
        "        if i[0] == 1 and i[1]*(2**x)<=1:\n",
        "            x += 1\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UKlKArUBTPJ",
        "colab_type": "text"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U1VtUxOz7f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Counter():\n",
        "    def __init__(self, hidden):\n",
        "        '''hidden is the number of hidden variables to use per cell'''\n",
        "        self.hidden = hidden\n",
        "\n",
        "        self.bits_lstm = nn.LSTM(hidden_size=hidden, batch_first=True, input_size=1).double().cuda() \n",
        "        self.bits_dense = torch.randn([hidden,1], dtype=float, device=device, requires_grad=True) \n",
        "        self.string_lstm = nn.LSTM(hidden_size=hidden, batch_first=True, input_size=2).double().cuda() \n",
        "        self.string_dense = torch.randn([hidden,1], dtype=float, device=device, requires_grad=True) \n",
        "\n",
        "        params = list(self.bits_lstm.parameters()) + list(self.string_lstm.parameters())\n",
        "        params.append(self.bits_dense)\n",
        "        params.append(self.string_dense)\n",
        "        self.optimizer = optim.Adam(params)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_sequence(seq):\n",
        "        '''converts a set of sequences with the same length from array or numpy into a correctly formatted tensor.'''\n",
        "        seq = torch.tensor(seq, device=device).double()\n",
        "        seq = seq.reshape([len(seq), -1, 1])\n",
        "        return seq\n",
        "\n",
        "    def predict(self, sequence):\n",
        "        '''takes a tensor, predicts the sum of the tensor, and compares to the target sum of the tensor. \n",
        "        Returns the loss and the predicted sum'''\n",
        "\n",
        "        floats = torch.rand_like(sequence)\n",
        "        bits,_ = self.bits_lstm(floats)\n",
        "        bits = bits @ self.bits_dense\n",
        "        bits = torch.log(bits**2)\n",
        "        combined = torch.cat([sequence, bits],2)\n",
        "        out, _ = self.string_lstm(combined)\n",
        "        add = torch.sigmoid(out @ self.string_dense)\n",
        "        count = add.sum(1).squeeze(1)\n",
        "\n",
        "        sequence = torch.cat([sequence, floats], 2)\n",
        "        target = self.true_sum(sequence)\n",
        "        loss = (count - target).pow(2)\n",
        "        return loss, count\n",
        "\n",
        "    def predict_multilength(self, sequences):\n",
        "        '''Takes a list of batches of tensors of different length. Predicts on each batch. Sums up the loss. Reduces to a single mean'''\n",
        "        loss = torch.tensor(0, device=device).double()\n",
        "        count= torch.tensor(0, device=device).double()\n",
        "        for s in sequences:\n",
        "            res    = self.predict(s)[0]\n",
        "            count += res.shape[0]\n",
        "            loss  += res.sum()\n",
        "        return loss / count\n",
        "\n",
        "    @staticmethod\n",
        "    def true_sum(sequence):\n",
        "        '''Determines the true sums of a batch of sequences to train against'''\n",
        "        res = []\n",
        "        for seq in sequence:\n",
        "            res.append(morris_count(seq))\n",
        "        res = np.array(res, dtype=float)\n",
        "        return torch.tensor(res, device=device).double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWFnUlWBqLM",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvC9waVe4EGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def round_partition(p):\n",
        "    '''Rounds a partition so that the sum of the partition equals the original sum'''\n",
        "    rounded = np.round(p).astype(int)\n",
        "    ind = len(rounded)-1\n",
        "    while rounded.sum() < p.sum():\n",
        "        rounded[ind] += 1\n",
        "        ind -= 1\n",
        "    return rounded\n",
        "\n",
        "def generate_data(length, total):\n",
        "    counts = np.random.dirichlet((np.arange(length)+1)**2) * total * 0.9\n",
        "    counts = round_partition(counts)\n",
        "\n",
        "    train_set = []\n",
        "    val_set = []\n",
        "    test_set = []\n",
        "    for i in range(1,length+1):\n",
        "        if counts[i-1] == 0:\n",
        "            continue\n",
        "        seqs = np.random.randint(0,2, size=[counts[i-1],i])\n",
        "        seqs = np.unique(seqs, axis=0)[:,:,None]\n",
        "        try:\n",
        "            train, val = train_test_split(seqs, test_size=2/9, shuffle=True)\n",
        "            train = Counter.convert_sequence(train)\n",
        "            val = Counter.convert_sequence(val)\n",
        "            train_set.append(train)\n",
        "            val_set.append(val)\n",
        "        except ValueError:\n",
        "            train = Counter.convert_sequence(seqs)\n",
        "            train_set.append(train)\n",
        "            continue\n",
        "    counts = np.random.dirichlet((np.arange(length, 2*length)+1)**2) * total * 0.1\n",
        "    counts = round_partition(counts)\n",
        "\n",
        "    for i in range(length):\n",
        "        if counts[i] == 0:\n",
        "            continue\n",
        "        seqs = np.random.randint(0,2, size=[counts[i],i+length+1])\n",
        "        seqs = np.unique(seqs, axis=0)[:,:,None]\n",
        "        seqs = Counter.convert_sequence(seqs)\n",
        "        test_set.append(seqs)\n",
        "\n",
        "    return train_set, val_set, test_set\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ekLB3rz96d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate all the strings and partition into train and test\n",
        "length = 64\n",
        "hidden = 10\n",
        "depth = 100\n",
        "\n",
        "output_folder = \"Part-8.2-Outputs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V28nvi7EGArd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train, val, test = generate_data(length,depth)\n",
        "\n",
        "# with open(\"%s/Data.pickle\"%output_folder, \"wb\") as f:\n",
        "#     pickle.dump([train, val, test], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k82PKEhGETm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"%s/Data.pickle\"%output_folder, \"rb\") as f:\n",
        "    train, val, test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIQ6ykY8G65T",
        "colab_type": "code",
        "outputId": "0ced169a-97fc-4d40-f015-de993ffef86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "trainsize = sum([x.shape[0] for x in train])\n",
        "valsize = sum([x.shape[0] for x in val])\n",
        "testsize = sum([x.shape[0] for x in test])\n",
        "print(trainsize, valsize, testsize)\n",
        "\n",
        "total = trainsize+valsize+testsize\n",
        "print(\"Total:\",total) \n",
        "print(\"Fraction %.3f %.3f %.3f\"%(trainsize/total, valsize/total, testsize/total))\n",
        "\n",
        "print(\"Train    string range: %d-%d\"%(min([x.shape[1] for x in train]), max([x.shape[1] for x in train])))\n",
        "print(\"Validate string range: %d-%d\"%(min([x.shape[1] for x in val]), max([x.shape[1] for x in val])))\n",
        "print(\"Test     string range: %d-%d\"%(min([x.shape[1] for x in test]), max([x.shape[1] for x in test])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62 29 10\n",
            "Total: 101\n",
            "Fraction 0.614 0.287 0.099\n",
            "Train    string range: 23-64\n",
            "Validate string range: 39-64\n",
            "Test     string range: 119-128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO19JkYIXSAU",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsuiwPh729fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train over all the training data\n",
        "model = Counter(hidden=hidden)\n",
        "\n",
        "history = []\n",
        "best = float('inf')\n",
        "patience = 10\n",
        "tol = 0.001\n",
        "count = 0\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1,1000000): \n",
        "    shuffle(train)\n",
        "    shuffle(val)\n",
        "    if epoch % 100 == 0:\n",
        "        train_loss = model.predict_multilength(train).item()\n",
        "        with torch.no_grad():\n",
        "            val_loss = model.predict_multilength(val).item()\n",
        "        history.append([train_loss, val_loss])\n",
        "        print(\"Epoch: %5d. Train Loss: %7.3f. Validation Loss: %7.3f. Elapsed: %7.3f\"%(epoch, train_loss, val_loss, (time()-start)/60))\n",
        "        start = time()\n",
        "\n",
        "        if val_loss + tol < best:\n",
        "            best = val_loss\n",
        "            count = 0\n",
        "            torch.save(model, \"%s/Model\"%output_folder)\n",
        "        else:\n",
        "            count += 1\n",
        "        if count >= patience:\n",
        "            break\n",
        "\n",
        "    #take the average loss over all the train data\n",
        "    loss = model.predict_multilength(train)   \n",
        "    #and update\n",
        "    model.optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    model.optimizer.step()\n",
        "\n",
        "# history = np.array(history)\n",
        "# np.save(\"%s/Train-History\"%output_folder, history)\n",
        "# torch.save(model, \"%s/Model\"%output_folder)\n",
        "\n",
        "# #display testing results\n",
        "# loss = model.predict_multilength(test)\n",
        "# print(\"Average Test Loss:\", loss.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azs8MF9xXe4v",
        "colab_type": "text"
      },
      "source": [
        "## Results Evaluation\n",
        "\n",
        "Same deal as in last time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuDksNrpXgGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(\"%s/Model\"%output_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Muev3LXZFZM",
        "colab_type": "code",
        "outputId": "93f0583e-eeec-4c7a-e6c5-03f47b0fbd27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "loss = model.predict_multilength(train)\n",
        "print(\"Average Train Loss:\", loss.item())\n",
        "loss = model.predict_multilength(val)\n",
        "print(\"Average Val   Loss:\", loss.item())\n",
        "loss = model.predict_multilength(test)\n",
        "print(\"Average Test  Loss:\", loss.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Train Loss: 0.6621275245173541\n",
            "Average Val   Loss: 0.40246617236868704\n",
            "Average Test  Loss: 2.0435234672654277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezqxGcQaZJgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = []\n",
        "pred = []\n",
        "size = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-glC-r96RjTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for length in range(1000,10000,1000):\n",
        "    depth = np.random.randint(1,10)\n",
        "    seq = np.random.randint(0,2,size=(depth,length,1))\n",
        "    seq = torch.tensor(seq).double().cuda()\n",
        "    l,p = model.predict(seq)\n",
        "    l = l.tolist()\n",
        "    p = p.tolist()\n",
        "    loss.extend(l)\n",
        "    pred.extend(p)\n",
        "    size.extend([length for _ in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKx59P_kRlWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true = []\n",
        "for l,p in zip(loss,pred):\n",
        "    t = p - np.sqrt(l)\n",
        "    if not isclose(t, int(t)):\n",
        "        t = p + np.sqrt(l)\n",
        "    true.append(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYrcM6hlRuph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = pd.DataFrame({\"Predicted\":pred, \"Loss\":loss, \"Length\":size, \"Real\":true})\n",
        "res.to_csv(\"%s/Large_testing-8.2\"%output_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvxS41viRwdJ",
        "colab_type": "code",
        "outputId": "7f3ae056-0746-4274-c2d2-47ae7d33f94c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "res = pd.read_csv(\"%s/Large_testing-8.2\"%output_folder)\n",
        "res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Length</th>\n",
              "      <th>Real</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.919267</td>\n",
              "      <td>0.006518</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.921876</td>\n",
              "      <td>0.006103</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.938727</td>\n",
              "      <td>0.003754</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.928309</td>\n",
              "      <td>0.005140</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.964871</td>\n",
              "      <td>0.001234</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>682</td>\n",
              "      <td>279.316328</td>\n",
              "      <td>70924.386353</td>\n",
              "      <td>9000</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>683</td>\n",
              "      <td>280.397408</td>\n",
              "      <td>72037.168505</td>\n",
              "      <td>9000</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684</th>\n",
              "      <td>684</td>\n",
              "      <td>279.052613</td>\n",
              "      <td>71317.097988</td>\n",
              "      <td>9000</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>685</td>\n",
              "      <td>282.923385</td>\n",
              "      <td>73942.327367</td>\n",
              "      <td>9000</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>686</td>\n",
              "      <td>286.071352</td>\n",
              "      <td>75664.248453</td>\n",
              "      <td>9000</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>687 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0   Predicted          Loss  Length  Real\n",
              "0             0    0.919267      0.006518       2   1.0\n",
              "1             1    0.921876      0.006103       2   1.0\n",
              "2             2    0.938727      0.003754       2   1.0\n",
              "3             3    0.928309      0.005140       2   1.0\n",
              "4             4    0.964871      0.001234       2   1.0\n",
              "..          ...         ...           ...     ...   ...\n",
              "682         682  279.316328  70924.386353    9000  13.0\n",
              "683         683  280.397408  72037.168505    9000  12.0\n",
              "684         684  279.052613  71317.097988    9000  12.0\n",
              "685         685  282.923385  73942.327367    9000  11.0\n",
              "686         686  286.071352  75664.248453    9000  11.0\n",
              "\n",
              "[687 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP71srE_Rzp1",
        "colab_type": "code",
        "outputId": "180b8afd-67ba-46e3-9482-64eaeac009b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "sns.set()\n",
        "sns.scatterplot(x=\"Real\", y=\"Predicted\", data=res, color='k')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa45b1e3320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOw0rOAlR4xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}